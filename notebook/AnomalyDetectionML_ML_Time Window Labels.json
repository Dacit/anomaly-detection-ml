{"paragraphs":[{"text":"%kryo-spark.dep\n\nz.reset()\nz.addRepo(\"Spark Packages Repo\").url(\"https://dl.bintray.com/spark-packages/maven\")\n\nz.addRepo(\"qaware-internal-snapshots\").url(\"https://www.qaware.de/nexus/content/repositories/qaware-internal-snapshots/\").username(\"f.huch\").password(\"\")\nz.load(\"de.qaware.mlwb:mlwb-impl:1.2-SNAPSHOT\")\n\nz.load(\"org.vegas-viz:vegas_2.11:0.3.11\")\nz.load(\"org.vegas-viz:vegas-spark_2.11:0.3.11\")\nz.load(\"sramirez:spark-infotheoretic-feature-selection:1.4.0\")\nz.load(\"org.nd4j:nd4j-native:0.9.1\")\nz.load(\"org.deeplearning4j:dl4j-spark_2.11:0.9.1_spark_2\")\nz.load(\"org.nd4j:nd4j-kryo_2.11:0.9.1\")\nz.load(\"org.datavec:datavec-api:0.9.1\")\nz.load(\"org.apache.mahout:mahout-spark_2.10:0.13.0\")\nz.load(\"org.apache.commons:commons-math3:3.6.1\")\n\nz.fetch","user":"anonymous","dateUpdated":"2018-01-21T15:47:06+0100","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: java.util.List[java.io.File] = [/opt/zeppelin/local-repo/de/qaware/mlwb/mlwb-impl/1.2-SNAPSHOT/mlwb-impl-1.2-SNAPSHOT.jar, /opt/zeppelin/local-repo/de/qaware/mlwb/mlwb-api/1.2-SNAPSHOT/mlwb-api-1.2-SNAPSHOT.jar, /opt/zeppelin/local-repo/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar, /opt/zeppelin/local-repo/de/qaware/mlwb/mlwb-dt/1.2-SNAPSHOT/mlwb-dt-1.2-SNAPSHOT.jar, /opt/zeppelin/local-repo/org/apache/solr/solr-solrj/6.5.1/solr-solrj-6.5.1.jar, /opt/zeppelin/local-repo/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar, /opt/zeppelin/local-repo/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar, /opt/zeppelin/local-repo/org/apache/httpcomponents/httpmime/4.4.1/httpmime-4.4.1.jar, /opt/zeppelin/local-repo/org/apache/zookeeper/zookeeper/3.4.6/zoo..."}]},"apps":[],"jobName":"paragraph_1514973395741_-564793432","id":"20171205-161552_1839513233","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:47:06+0100","dateFinished":"2018-01-21T15:47:17+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:63"},{"text":"%kryo-spark\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.Encoders\nimport de.qaware.mlwb.api.Counter\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.linalg.Vector\nimport collection.JavaConverters._\nimport java.sql.Timestamp\nimport de.qaware.mlwb.api._\nimport de.qaware.mlwb.impl.sparksolr.MetricsServiceImpl\nimport org.apache.spark.storage.StorageLevel\n\norg.bytedeco.javacpp.Pointer.maxPhysicalBytes\norg.bytedeco.javacpp.Pointer.maxBytes\n\nval trainFromFile: RDD[Row] = sc.objectFile(\"/anomaly-detection-ml/training/part-*\", 200)\nval validateFromFile: RDD[Row] = sc.objectFile(\"/anomaly-detection-ml/validate/part-*\", 200)\nval testFromFile: RDD[Row] = sc.objectFile(\"/anomaly-detection-ml/test/part-*\", 200)\n\nval train = sqlc.createDataFrame(trainFromFile, trainFromFile.first.schema).persist(StorageLevel.OFF_HEAP)\n\n// Spark except does not work with UDT in 2.1.1 :(\nval excludeBC = sc.broadcast(train.map(r => r.getAs[String](\"host\") + r.getAs[String](\"procs\") + r.getAs[java.sql.Timestamp](\"ts\").toString).collect)\n\nval validate = sqlc.createDataFrame(validateFromFile, validateFromFile.first.schema).filter(r => {\n    val exclude = excludeBC.value\n    val comp = r.getAs[String](\"host\") + r.getAs[String](\"procs\")  + r.getAs[java.sql.Timestamp](\"ts\").toString\n    \n    exclude.find(comp == _).isEmpty\n}).persist(StorageLevel.OFF_HEAP)\n\nval test = sqlc.createDataFrame(testFromFile, testFromFile.first.schema).persist(StorageLevel.OFF_HEAP)","user":"anonymous","dateUpdated":"2018-01-21T15:47:09+0100","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.Encoders\nimport de.qaware.mlwb.api.Counter\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.linalg.Vector\nimport collection.JavaConverters._\nimport java.sql.Timestamp\nimport de.qaware.mlwb.api._\nimport de.qaware.mlwb.impl.sparksolr.MetricsServiceImpl\nimport org.apache.spark.storage.StorageLevel\nres1: Long = 7635730432\nres2: Long = 3817865216\ntrainFromFile: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[1] at objectFile at <console>:46\nvalidateFromFile: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[3] at objectFile at <console>:45\ntestFromFile: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[5] at objectFile at <console>:45\ntrain: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [host: string, procs: string ... 4 more fields]\nexcludeBC: org.apache.spark.broadcast.Broadcast[Array[String]] = Broadcast(5)\nvalidate: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [host: string, procs: string ... 4 more fields]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [host: string, procs: string ... 4 more fields]\n"}]},"apps":[],"jobName":"paragraph_1514973395755_-580952886","id":"20171205-161613_1738844813","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:47:09+0100","dateFinished":"2018-01-21T15:48:18+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:64"},{"text":"%md\n\n# 3.1 General Things","user":"anonymous","dateUpdated":"2018-01-20T12:26:37+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>3.1 General Things</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1514973395756_-582876630","id":"20170927-160403_1451261299","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-20T12:26:37+0100","dateFinished":"2018-01-20T12:26:40+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:65"},{"text":"%kryo-spark\n\nclass CustomCrossValidator extends org.apache.spark.ml.tuning.CrossValidator {\n    import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n    import org.apache.spark.mllib.util.MLUtils\n    import org.apache.spark.sql.{DataFrame, Dataset}\n    import com.github.fommil.netlib.F2jBLAS\n    import org.apache.spark.ml.param._\n    import org.apache.spark.ml.util._\n    import org.apache.spark.ml._\n    import spark.implicits._\n    \n    private val f2jBLAS = new F2jBLAS\n    \n    def customFit[T](train: Dataset[T], validate: Dataset[T]): org.apache.spark.ml.tuning.CrossValidatorModel = {\n        val schema = train.schema\n        transformSchema(schema, logging = true)\n        val sparkSession = train.sparkSession\n        val est = $(estimator)\n        val eval = $(evaluator)\n        val epm = $(estimatorParamMaps)\n        val numModels = epm.length\n        val metrics = new Array[Double](epm.length)\n        val splits = MLUtils.kFold(train.toDF.rdd, $(numFolds), $(seed))\n        \n        val unbalancedValidationSplits = validate.toDF.randomSplit(Array.fill($(numFolds)) (1.0 / $(numFolds)), $(seed)).map(_.cache)\n        \n        splits.zipWithIndex.foreach { case ((training, validation), splitIndex) =>\n          val trainingDataset = sparkSession.createDataFrame(training, schema).cache()\n          val validationDataset = sparkSession.createDataFrame(validation, schema).cache()\n          // multi-model training\n          logDebug(s\"Train split $splitIndex with multiple sets of parameters.\")\n          val models = est.fit(trainingDataset, epm).asInstanceOf[Seq[Model[_]]]\n          trainingDataset.unpersist()\n          var i = 0\n          while (i < numModels) {\n            // TODO: duplicate evaluator to take extra params from input\n            val metric = eval.evaluate(models(i).transform(validationDataset.union(unbalancedValidationSplits(splitIndex)), epm(i)))\n            // threshold for max f1 score\n            logDebug(s\"Got metric for model trained with ${epm(i)}.\")\n            metrics(i) += metric\n            i += 1\n          }\n          validationDataset.unpersist()\n        }\n        \n        f2jBLAS.dscal(numModels, 1.0 / $(numFolds), metrics, 1)\n        logInfo(s\"Average cross-validation metrics: ${metrics.toSeq}\")\n        val (bestMetric, bestIndex) =\n          if (eval.isLargerBetter) metrics.zipWithIndex.maxBy(_._1)\n          else metrics.zipWithIndex.minBy(_._1)\n        logInfo(s\"Best set of parameters:\\n${epm(bestIndex)}\")\n        logInfo(s\"Best cross-validation metric: $bestMetric.\")\n        val bestModel = est.fit(train, epm(bestIndex)).asInstanceOf[Model[_]]\n        val constructor = classOf[org.apache.spark.ml.tuning.CrossValidatorModel].getConstructors()(0)\n        constructor.setAccessible(true)\n        \n        copyValues(constructor.newInstance(uid, bestModel, metrics).asInstanceOf[org.apache.spark.ml.tuning.CrossValidatorModel].setParent(this))\n    }\n}","user":"anonymous","dateUpdated":"2018-01-21T15:47:12+0100","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class CustomCrossValidator\n"}]},"apps":[],"jobName":"paragraph_1514973395757_-583261379","id":"20171221-101320_884789658","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:47:18+0100","dateFinished":"2018-01-21T15:48:19+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:66"},{"text":"%kryo-spark\nimport org.apache.spark.ml.tuning.ParamGridBuilder\nimport org.apache.spark.ml.param.ParamMap\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.ml.{Estimator, Model}\n\ndef tune[T <: Model[T], D](estimator: Estimator[T], grid: Array[ParamMap], train: Dataset[D], validate: Dataset[D]): T = {\n    val evaluator = new BinaryClassificationEvaluator()\n        .setLabelCol(\"manualLabel\")\n        .setRawPredictionCol(\"prediction\")\n        .setMetricName(\"areaUnderPR\")\n    \n    val result = new CustomCrossValidator()\n        .setNumFolds(4)\n        .setEvaluator(evaluator)\n        .setEstimator(estimator)\n        .setEstimatorParamMaps(grid)\n        .customFit(train, validate)\n    \n    result.bestModel.asInstanceOf[T]\n}","user":"anonymous","dateUpdated":"2018-01-21T15:47:15+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.tuning.ParamGridBuilder\nimport org.apache.spark.ml.param.ParamMap\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.ml.{Estimator, Model}\ntune: [T <: org.apache.spark.ml.Model[T], D](estimator: org.apache.spark.ml.Estimator[T], grid: Array[org.apache.spark.ml.param.ParamMap], train: org.apache.spark.sql.Dataset[D], validate: org.apache.spark.sql.Dataset[D])T\n"}]},"apps":[],"jobName":"paragraph_1514973395757_-583261379","id":"20170927-160402_936257691","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:48:18+0100","dateFinished":"2018-01-21T15:48:20+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67"},{"text":"%kryo-spark\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n\ndef eval[T <: Model[T]](model: T, test: Dataset[_]): Tuple2[Double, Double] = {\n    val transformed = model.transform(test).cache\n    \n    val tp = transformed.filter($\"manualLabel\" > 0).filter($\"prediction\" > 0).count.toDouble\n    val fp = transformed.filter($\"manualLabel\" === 0).filter($\"prediction\" > 0).count.toDouble\n    val fn = transformed.filter($\"manualLabel\" > 0).filter($\"prediction\" === 0).count.toDouble\n    \n    val precision = tp / (tp + fp)\n    val recall = tp / (tp + fn)\n    \n    (precision, recall)\n}","user":"anonymous","dateUpdated":"2018-01-21T15:47:20+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\neval: [T <: org.apache.spark.ml.Model[T]](model: T, test: org.apache.spark.sql.Dataset[_])(Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1514973395758_-582107132","id":"20171221-161347_225259132","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:48:19+0100","dateFinished":"2018-01-21T15:48:21+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:68"},{"text":"%kryo-spark\nimport java.sql.Timestamp\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.ml.linalg.Vectors\n\ncase class Scaled(host: String, procs: String, ts: java.sql.Timestamp, manualLabel: Double, scaledFeatures: org.apache.spark.ml.linalg.Vector)\n\ndef normalizeTo(minutes: Int, ts: Timestamp, offset: Int): Timestamp = {\n    new Timestamp(((ts.getTime - offset * 60 * 1000) / (60 * 1000 * minutes)) * (60 * 1000 * minutes))\n}\n\ndef scaleTimeWindowOffset(minutes: Int, original: Dataset[_], offset: Int): Dataset[Scaled] = {\n    if (offset >= minutes) {\n        throw new IllegalArgumentException(\"Offset must be smaller than window! Window: \" + minutes + \", offset: \" + offset)\n    }\n    original.toDF\n        .groupByKey(r => (r.getAs[String](\"host\"), r.getAs[String](\"procs\"), normalizeTo(minutes, r.getAs[Timestamp](\"ts\"), offset)))\n        .flatMapGroups((k, vs) => {\n            val vsList = vs.toList\n            \n            if (vsList.size != minutes) {\n                Iterator()\n            } else {\n                val label = if (vsList.map(_.getAs[Double](\"manualLabel\")).reduce(_ + _) > (vsList.size.toDouble / 2.0)) 1.0 else 0.0\n                \n                val average = Vectors.dense(vsList.map(_.getAs[org.apache.spark.ml.linalg.Vector](\"scaledFeatures\").toArray).reduce(_.zip(_).map(t => t._1 + t._2)).map(_.toDouble / minutes))\n            \n                Iterator(Scaled(k._1, k._2, k._3, label, average))\n            }\n        })\n}\n\ndef scaleTimeWindow(minutes: Int, original: Dataset[_]): Dataset[Scaled] = {\n    (0 until minutes).map(scaleTimeWindowOffset(minutes, original, _)).reduce(_.union(_))\n}","user":"anonymous","dateUpdated":"2018-01-21T15:47:22+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.sql.Timestamp\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.ml.linalg.Vectors\ndefined class Scaled\nnormalizeTo: (minutes: Int, ts: java.sql.Timestamp, offset: Int)java.sql.Timestamp\nscaleTimeWindowOffset: (minutes: Int, original: org.apache.spark.sql.Dataset[_], offset: Int)org.apache.spark.sql.Dataset[Scaled]\nscaleTimeWindow: (minutes: Int, original: org.apache.spark.sql.Dataset[_])org.apache.spark.sql.Dataset[Scaled]\n"}]},"apps":[],"jobName":"paragraph_1514973395769_-575566401","id":"20171004-110953_1553812280","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:48:20+0100","dateFinished":"2018-01-21T15:48:23+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:69"},{"text":"%kryo-spark\nval train9min = scaleTimeWindow(9, train).cache\nval validate9min = scaleTimeWindow(9, validate).cache\nval test9min = scaleTimeWindow(9, test).cache\ntrain9min.count\nvalidate9min.count\ntest9min.count","user":"anonymous","dateUpdated":"2018-01-20T12:26:39+0100","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"train9min: org.apache.spark.sql.Dataset[Scaled] = [host: string, procs: string ... 3 more fields]\nvalidate9min: org.apache.spark.sql.Dataset[Scaled] = [host: string, procs: string ... 3 more fields]\ntest9min: org.apache.spark.sql.Dataset[Scaled] = [host: string, procs: string ... 3 more fields]\nres15: Long = 149213\nres16: Long = 3934849\nres17: Long = 3412140\n"}]},"apps":[],"jobName":"paragraph_1514973395770_-574412154","id":"20171004-111011_1559709766","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-15T17:41:16+0100","dateFinished":"2018-01-15T18:02:38+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:70"},{"text":"%kryo-spark\n","user":"anonymous","dateUpdated":"2018-01-20T12:26:40+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1516021502260_-1585351660","id":"20180115-140502_1772852222","dateCreated":"2018-01-15T14:05:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:71"},{"text":"%kryo-spark\nval train15min = scaleTimeWindow(15, train).cache\nval validate15min = scaleTimeWindow(15, validate).cache\nval test15min = scaleTimeWindow(15, test).cache\ntrain15min.count\nvalidate15min.count\ntest15min.count","user":"anonymous","dateUpdated":"2018-01-21T15:47:27+0100","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"train15min: org.apache.spark.sql.Dataset[Scaled] = [host: string, procs: string ... 3 more fields]\nvalidate15min: org.apache.spark.sql.Dataset[Scaled] = [host: string, procs: string ... 3 more fields]\ntest15min: org.apache.spark.sql.Dataset[Scaled] = [host: string, procs: string ... 3 more fields]\nres15: Long = 148669\nres16: Long = 3933475\nres17: Long = 3410439\n"}]},"apps":[],"jobName":"paragraph_1514973395770_-574412154","id":"20171004-111009_1909992413","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:48:21+0100","dateFinished":"2018-01-21T16:16:45+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:72"},{"text":"%md\n\n# 3.2 Models","user":"anonymous","dateUpdated":"2018-01-20T12:26:40+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>3.2 Models</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1514973395771_-574796903","id":"20171004-154131_816883771","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-20T12:26:41+0100","dateFinished":"2018-01-20T12:26:41+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:73"},{"text":"%kryo-spark\ndef gradientBoostedTrees[T](tr: Dataset[T], vl: Dataset[T], tst: Dataset[T]): Tuple2[Double, Double] = {\n    import org.apache.spark.ml.classification.{GBTClassifier, GBTClassificationModel}\n\n    val model = new GBTClassifier()\n        .setLabelCol(\"manualLabel\")\n        .setFeaturesCol(\"scaledFeatures\")\n        .setMaxIter(10)\n    \n    val paramGrid = new ParamGridBuilder()\n        .addGrid(model.impurity, Array(\"gini\"))\n        .addGrid(model.maxBins, Array(32, 64))\n        .addGrid(model.maxDepth, Array(7))\n        .addGrid(model.minInfoGain, Array(0.0, 0.001))\n        .addGrid(model.minInstancesPerNode, Array(2, 3))\n        .addGrid(model.stepSize, Array(0.5))\n        .addGrid(model.subsamplingRate, Array(1.0))\n        .build()\n        \n    val tuned = tune(model, paramGrid, tr, vl)\n        \n    println(\"Impurity: \" + tuned.asInstanceOf[GBTClassificationModel].getImpurity)\n    println(\"Max Bins: \" + tuned.asInstanceOf[GBTClassificationModel].getMaxBins)\n    println(\"Max Depth: \" + tuned.asInstanceOf[GBTClassificationModel].getMaxDepth)\n    println(\"Min Info Gain: \" + tuned.asInstanceOf[GBTClassificationModel].getMinInfoGain)\n    println(\"Min Instances per Node: \" + tuned.asInstanceOf[GBTClassificationModel].getMinInstancesPerNode)\n    println(\"Step Size: \" + tuned.asInstanceOf[GBTClassificationModel].getStepSize)\n    println(\"Subsampling rate: \" + tuned.asInstanceOf[GBTClassificationModel].getSubsamplingRate)\n    \n     eval(tuned, tst)\n}","user":"anonymous","dateUpdated":"2018-01-21T15:47:37+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"gradientBoostedTrees: [T](tr: org.apache.spark.sql.Dataset[T], vl: org.apache.spark.sql.Dataset[T], tst: org.apache.spark.sql.Dataset[T])(Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1514973395773_-577105397","id":"20171004-163306_1430029021","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T15:48:23+0100","dateFinished":"2018-01-21T16:16:45+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:74"},{"text":"%kryo-spark\ndef multiLayerPerceptron[T](tr: Dataset[T], vl: Dataset[T], tst: Dataset[T]): Tuple2[Double, Double] = {\n    import org.apache.spark.ml.classification.{MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel}\n\n    val model = new MultilayerPerceptronClassifier()\n        .setLabelCol(\"manualLabel\")\n        .setFeaturesCol(\"scaledFeatures\")\n        .setMaxIter(100)\n    \n    val paramGrid = new ParamGridBuilder()\n        .addGrid(model.layers, Array(Array(231, 200, 2)))\n        .addGrid(model.solver, Array(\"l-bfgs\"))\n        .addGrid(model.stepSize, Array(0.01, 0.001))\n        .addGrid(model.tol, Array(0.0001, 0.000001))\n        .build()\n        \n    val tuned = tune(model, paramGrid, tr, vl)\n    \n    println(\"Layers: \" + tuned.asInstanceOf[MultilayerPerceptronClassificationModel].layers.mkString(\",\"))\n    println(\"Solver: \" + tuned.asInstanceOf[MultilayerPerceptronClassificationModel].parent.asInstanceOf[MultilayerPerceptronClassifier].getSolver)\n    println(\"Step Size: \" + tuned.asInstanceOf[MultilayerPerceptronClassificationModel].parent.asInstanceOf[MultilayerPerceptronClassifier].getStepSize)\n    println(\"Tol: \" + tuned.asInstanceOf[MultilayerPerceptronClassificationModel].parent.asInstanceOf[MultilayerPerceptronClassifier].getTol)\n    \n     eval(tuned, tst)\n}","user":"anonymous","dateUpdated":"2018-01-21T15:47:40+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"multiLayerPerceptron: [T](tr: org.apache.spark.sql.Dataset[T], vl: org.apache.spark.sql.Dataset[T], tst: org.apache.spark.sql.Dataset[T])(Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1514973395773_-577105397","id":"20171004-163904_1187092239","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-21T16:16:46+0100","dateFinished":"2018-01-21T16:16:46+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:75"},{"text":"%md\n\n# 3.3 Evaluation for different time windows","user":"anonymous","dateUpdated":"2018-01-20T12:26:41+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>3.3 Evaluation for different time windows</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1514973395778_-589802110","id":"20171002-131515_71134535","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-20T12:26:41+0100","dateFinished":"2018-01-20T12:26:41+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:76"},{"text":"%md\n\n## 3.3.4. Gradient boosted tree","user":"anonymous","dateUpdated":"2018-01-20T12:26:41+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>3.3.4. Gradient boosted tree</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1514973395803_-587108868","id":"20171002-131338_853782304","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-20T12:26:41+0100","dateFinished":"2018-01-20T12:26:41+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:77"},{"text":"%kryo-spark\ngradientBoostedTrees(train, validate, test)","user":"anonymous","dateUpdated":"2018-01-20T12:26:41+0100","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Impurity: entropy\nMax Bins: 32\nMax Depth: 7\nMin Info Gain: 0.001\nMin Instances per Node: 2\nStep Size: 0.5\nSubsampling rate: 1.0\nres19: (Double, Double) = (0.19169151899046163,0.17907715686951717)\n"}]},"apps":[],"jobName":"paragraph_1514973395804_-589032613","id":"20171002-131017_1559126385","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-09T10:03:52+0100","dateFinished":"2018-01-09T13:09:30+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:78"},{"text":"%kryo-spark\ngradientBoostedTrees(train9min, validate9min, test9min)","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Impurity: gini\nMax Bins: 64\nMax Depth: 7\nMin Info Gain: 0.0\nMin Instances per Node: 2\nStep Size: 0.5\nSubsampling rate: 1.0\nres18: (Double, Double) = (0.18086304338588366,0.1961925394977932)\n"}]},"apps":[],"jobName":"paragraph_1514973395804_-589032613","id":"20171004-164725_381943416","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-15T18:02:39+0100","dateFinished":"2018-01-15T23:05:57+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:79"},{"text":"%kryo-spark\ngradientBoostedTrees(train15min, validate15min, test15min)","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514973395805_-589417361","id":"20171004-164738_947161312","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-20T12:56:15+0100","dateFinished":"2018-01-20T03:38:35+0100","status":"ABORT","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:80"},{"text":"%kryo-spark\nimport org.apache.spark.ml.classification.{GBTClassifier, GBTClassificationModel}\nval gbt15 = new GBTClassifier()\n    .setLabelCol(\"manualLabel\")\n    .setFeaturesCol(\"scaledFeatures\")\n    .setImpurity(\"gini\")\n    .setMaxBins(64)\n    .setMaxDepth(7)\n    .setMinInfoGain(0.0)\n    .setMinInstancesPerNode(2)\n    .setStepSize(0.5)\n    .setSubsamplingRate(1.0)\n    .fit(train15min)\n    \neval(gbt15, test15min)","user":"anonymous","dateUpdated":"2018-01-21T16:16:46+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.classification.{GBTClassifier, GBTClassificationModel}\ngbt15: org.apache.spark.ml.classification.GBTClassificationModel = GBTClassificationModel (uid=gbtc_ec06e35bf64a) with 20 trees\nres19: (Double, Double) = (0.27564250095895665,0.16574024955601172)\n"}]},"apps":[],"jobName":"paragraph_1516546066093_1648937153","id":"20180121-154746_147978908","dateCreated":"2018-01-21T15:47:46+0100","dateStarted":"2018-01-21T16:16:46+0100","dateFinished":"2018-01-21T17:10:48+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:81"},{"text":"%md\n\n## 3.3.5. Multi-layer perceptron","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>3.3.5. Multi-layer perceptron</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1514973395805_-589417361","id":"20171002-131357_741132421","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-20T12:26:42+0100","dateFinished":"2018-01-20T12:26:42+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:82"},{"text":"%kryo-spark\nmultiLayerPerceptron(train, validate, test)","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Layers: 231,200,2\nSolver: l-bfgs\nStep Size: 0.001\nTol: 1.0E-6\nres15: (Double, Double) = (0.19826904553100336,0.15876908199212544)\n"}]},"apps":[],"jobName":"paragraph_1514973395811_-602498824","id":"20170927-163402_1897325982","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-15T11:19:53+0100","dateFinished":"2018-01-15T13:58:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:83"},{"text":"%kryo-spark\nmultiLayerPerceptron(train9min, validate9min, test9min)","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":false,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Layers: 231,200,2\nSolver: l-bfgs\nStep Size: 0.001\nTol: 1.0E-6\nres19: (Double, Double) = (0.3546560233003425,0.15154937368196642)\n"}]},"apps":[],"jobName":"paragraph_1514973395811_-602498824","id":"20171004-164757_543892039","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-15T18:02:39+0100","dateFinished":"2018-01-16T01:39:44+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:84"},{"text":"%kryo-spark\nmultiLayerPerceptron(train15min, validate15min, test15min)","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514973395812_-604422569","id":"20171004-164825_1539308820","dateCreated":"2018-01-03T10:56:35+0100","dateStarted":"2018-01-19T22:54:26+0100","dateFinished":"2018-01-16T02:09:15+0100","status":"ABORT","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:85"},{"text":"%kryo-spark\nimport org.apache.spark.ml.classification.{MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel}\nval mlp15 = new MultilayerPerceptronClassifier()\n    .setLabelCol(\"manualLabel\")\n    .setFeaturesCol(\"scaledFeatures\")\n    .setLayers(Array(231, 200, 2))\n    .setSolver(\"l-bfgs\")\n    .setStepSize(0.001)\n    .setTol(0.000001)\n    .fit(train15min)\n    \neval(mlp15, test15min)","user":"anonymous","dateUpdated":"2018-01-21T16:16:46+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.classification.{MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel}\nmlp15: org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel = mlpc_8fcd2230b70d\nres21: (Double, Double) = (0.4126197721499887,0.37841640334894017)\n"}]},"apps":[],"jobName":"paragraph_1516546284234_723740286","id":"20180121-155124_1037889118","dateCreated":"2018-01-21T15:51:24+0100","dateStarted":"2018-01-21T16:16:46+0100","dateFinished":"2018-01-21T17:40:48+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:86"},{"text":"","user":"anonymous","dateUpdated":"2018-01-20T12:26:42+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514973395819_-605576815","id":"20171004-123546_857963876","dateCreated":"2018-01-03T10:56:35+0100","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:87"}],"name":"AnomalyDetectionML/ML/Time Window Labels","id":"2D4H86UVC","angularObjects":{"2CZU9K4SP:shared_process":[],"2D18HK2TW:shared_process":[],"2D15EVSM5:shared_process":[],"2D4K6GGH4:shared_process":[],"2D2FQENTY:shared_process":[],"2CYJWH63V:shared_process":[],"2CY5C8M4U:shared_process":[],"2D2NZHKM4:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}