{"paragraphs":[{"text":"%dep\n\nz.reset\nz.addRepo(\"Spark Packages Repo\").url(\"https://dl.bintray.com/spark-packages/maven\")\nz.addRepo(\"qaware-internal-snapshots\").url(\"https://www.qaware.de/nexus/content/repositories/qaware-internal-snapshots/\").username(\"f.huch\")\nz.load(\"de.qaware.mlwb:featureextractor:1.0-SNAPSHOT\")\nz.load(\"de.qaware.mlwb:mlwb-impl:1.2-SNAPSHOT\")\nz.load(\"org.apache.commons:commons-math3:3.6.1\")\n\nz.fetch","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: java.util.List[java.io.File] = [/opt/zeppelin/local-repo/de/qaware/mlwb/featureextractor/1.0-SNAPSHOT/featureextractor-1.0-SNAPSHOT.jar, /opt/zeppelin/local-repo/de/qaware/mlwb/mlwb-impl/1.2-SNAPSHOT/mlwb-impl-1.2-SNAPSHOT.jar, /opt/zeppelin/local-repo/de/qaware/mlwb/mlwb-api/1.2-SNAPSHOT/mlwb-api-1.2-SNAPSHOT.jar, /opt/zeppelin/local-repo/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar, /opt/zeppelin/local-repo/de/qaware/mlwb/mlwb-dt/1.2-SNAPSHOT/mlwb-dt-1.2-SNAPSHOT.jar, /opt/zeppelin/local-repo/org/apache/solr/solr-solrj/6.5.1/solr-solrj-6.5.1.jar, /opt/zeppelin/local-repo/org/apache/httpcomponents/httpclient/4.4.1/httpclient-4.4.1.jar, /opt/zeppelin/local-repo/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar, /opt/zeppelin/local-repo/org/apache/httpcompon..."}]},"apps":[],"jobName":"paragraph_1512380989578_2090434157","id":"20170706-112009_1863775061","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:26"},{"text":"%spark\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.sql.Encoders\nimport java.sql.Timestamp\nimport com.google.common.collect.Iterators\nimport de.qaware.mlwb.api._\nimport collection.JavaConverters._\nimport util.control.Breaks._\nimport org.apache.spark.sql.SaveMode\nimport de.qaware.mlwb.impl.sparksolr.MetricsServiceImpl\nimport org.apache.spark.sql.SaveMode","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.Dataset\n\nimport org.apache.spark.sql.Encoders\n\nimport java.sql.Timestamp\n\nimport com.google.common.collect.Iterators\n\nimport de.qaware.mlwb.api._\n\nimport collection.JavaConverters._\n\nimport util.control.Breaks._\n\nimport org.apache.spark.sql.SaveMode\n\nimport de.qaware.mlwb.impl.sparksolr.MetricsServiceImpl\n\nimport org.apache.spark.sql.SaveMode\n"}]},"apps":[],"jobName":"paragraph_1512380989579_2090049408","id":"20170718-155252_1934180693","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:27"},{"text":"%md\n\nRun the following notebooks first (and don't use run all, as this won't work for a zeppelin bug):","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Run the following notebooks first (and don&rsquo;t use run all, as this won&rsquo;t work for a zeppelin bug):</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1512380989580_2088125663","id":"20171024-095712_989960455","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:28"},{"text":"%spark\n// Feature definitions\nz.runNote(\"2CQSB8UPG\")","dateUpdated":"2017-12-04T10:49:57+0100","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1512380989581_2087740915","id":"20170718-123141_943417710","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:29"},{"text":"%md\n# Methods for feature creation","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Methods for feature creation</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1512380989582_2088895161","id":"20171024-095724_1875950622","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30"},{"text":"%spark\ndef combFun(comb: Combinator) = comb match {\n    case Addition => ((l: Double, r: Double) => if (l < 0 || r < 0) -1.0 else l + r)\n    case Substraction => ((l: Double, r: Double) => if (l < 0 || r < 0) -1.0 else l - r)\n    case Multiplication => ((l: Double, r: Double) => if (l < 0 || r < 0) -1.0 else l * r)\n    case Division => ((l: Double, r: Double) => if (l < 0 || r < 0 || r == 0.0) -1.0 else l / r)\n}\n\ndef combString(comb: Combinator) = comb match {\n    case Addition => \" + \"\n    case Substraction => \" - \"\n    case Multiplication => \" * \"\n    case Division => \" / \"\n}","dateUpdated":"2017-12-04T10:53:31+0100","config":{"tableHide":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n\n\n\n<console>:74: warning: match may not be exhaustive.\nIt would fail on the following inputs: Addition, Division, Multiplication, Substraction\n       def combFun(comb: Combinator) = comb match {\n                                       ^\n\ncombFun: (comb: Combinator)(Double, Double) => Double\n\n\n\n\n<console>:75: warning: match may not be exhaustive.\nIt would fail on the following inputs: Addition, Division, Multiplication, Substraction\n       def combString(comb: Combinator) = comb match {\n                                          ^\n\ncombString: (comb: Combinator)String\n"}]},"apps":[],"jobName":"paragraph_1512380989582_2088895161","id":"20170718-155311_304436357","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:31"},{"text":"%spark\ndef leftCombine(left: Dataset[Counter], right: Double, comb: Combinator): Dataset[Counter] = {\n    left.map(c => {\n        c.getValuePoints.asScala.foreach(vp => vp.setValue(combFun(comb)(vp.getValue, right)))\n        c.getMetric.setName(\"(\" + c.getMetric.getName + combString(comb) + right + \")\")\n        c\n    }) (Encoders.bean(classOf[Counter]))\n}\n\ndef rightCombine(left: Double, right: Dataset[Counter], comb: Combinator): Dataset[Counter] = {\n    right.map(c => {\n        c.getValuePoints.asScala.foreach(vp => vp.setValue(combFun(comb)(left, vp.getValue)))\n        c.getMetric.setName(\"(\" + left + combString(comb) + c.getMetric.getName + \")\")\n        c\n    }) (Encoders.bean(classOf[Counter]))\n}\n\ndef biCombine(left: Dataset[Counter], right: Dataset[Counter], comb: Combinator): Dataset[Counter] = {\n    val fun = combFun(comb)\n    \n    left.joinWith(right, (right.col(\"metric.host\") === left.col(\"metric.host\")).and(right.col(\"metric.procs\") === left.col(\"metric.procs\"))).map(t => {\n        val itl = Iterators.peekingIterator(t._1.getValuePoints.iterator)\n        val itr = Iterators.peekingIterator(t._2.getValuePoints.iterator)\n        \n        val c = new Counter(new Metric(\"(\" + t._1.getMetric.getName + combString(comb) + t._2.getMetric.getName + \")\", t._1.getMetric.getHost, t._1.getMetric.getProcs))\n        while (itl.hasNext && itr.hasNext) {\n            breakable {\n                // continue loop until both iterators are on same date\n                if (itl.peek.getDate != itr.peek.getDate) {\n                    if (itl.peek.getDate.before(itr.peek.getDate)) itl.next else itr.next\n                    break\n                }\n                // Create new point at that date\n                val left = itl.next\n                c.getValuePoints.add(new ValuePoint(fun(left.getValue, itr.next.getValue), left.getDate))\n            }\n        }\n        c\n    }) (Encoders.bean(classOf[Counter]))\n    // If the date ranges do not match, result could be empty\n    .filter(!_.getValuePoints.isEmpty)\n}","dateUpdated":"2017-12-04T10:53:58+0100","config":{"tableHide":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nleftCombine: (left: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter], right: Double, comb: Combinator)org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n\nrightCombine: (left: Double, right: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter], comb: Combinator)org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n\nbiCombine: (left: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter], right: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter], comb: Combinator)org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n"}]},"apps":[],"jobName":"paragraph_1512380989583_2088510412","id":"20170718-155315_919836478","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:32"},{"text":"%spark\ndef derivePoint(previous: ValuePoint, point: ValuePoint): ValuePoint = {\n    if (previous.getValue == -1.0 || point.getValue == -1.0) {\n        new Valuepoint(-1.0, point.getDate)\n    } else {\n        new ValuePoint((point.getValue - previous.getValue) / ((point.getDate.getTime - previous.getDate.getTime) / 60000), point.getDate)\n    }\n}\n\ndef derive(data: Dataset[Counter]): Dataset[Counter] = {\n    data.map(c => {\n        val deriv = new Counter(new Metric(\"d/dx (\" + c.getMetric.getName + \")\", c.getMetric.getHost, c.getMetric.getProcs))\n        val vp = c.getValuePoints.iterator\n        \n        // Create derivative for first two points (first point gets same derivative as second point)\n        val first = vp.next\n        val second = vp.next\n        deriv.getValuePoints.add(new ValuePoint(derivePoint(first, second).getValue, first.getDate))\n        deriv.getValuePoints.add(derivePoint(first, second))\n        \n        // Create derivative for all remaining\n        var previous = second\n        while (vp.hasNext) {\n            val point = vp.next\n            deriv.getValuePoints.add(derivePoint(previous, point))\n            previous = point\n        }\n        deriv\n    }) (Encoders.bean(classOf[Counter]))\n}\n\ndef max(data: Dataset[Counter], inp: Double): Dataset[Counter] = {\n    data.map(c => {\n        c.getValuePoints.asScala.foreach(vp => if (vp.getValue < inp) vp.setValue(-1.0))\n        c.getMetric.setName(\"incl\" + c.getMetric.getName)\n        c\n    }) (Encoders.bean(classOf[Counter]))\n}","dateUpdated":"2017-12-04T11:11:05+0100","config":{"tableHide":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nderivePoint: (previous: de.qaware.mlwb.api.ValuePoint, point: de.qaware.mlwb.api.ValuePoint)de.qaware.mlwb.api.ValuePoint\n\nderive: (data: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter])org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n\nmax: (data: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter], inp: Double)org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n"}]},"apps":[],"jobName":"paragraph_1512380989584_2098898633","id":"20170718-155326_274202396","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:33"},{"text":"%spark\ndef stripProcessId(c: Counter): Counter = {\n    val key = \"\\\\Process(java\"\n    val name = c.getMetric.getName\n    \n    if (name.contains(key) && c.getMetric.getProcs == \"wls2\") {\n        c.getMetric.setName(name.replace(\"#1\", \"\"))\n    }\n    return c\n}\n\ndef stripServerRuntimes(c: Counter): Counter = {\n    val key = \"ServerRuntime\"\n    val name = c.getMetric.getName\n    val host = c.getMetric.getHost\n    \n    if (name.contains(host) && name.contains(key) &&  name.indexOf(key) < name.indexOf(host)) {\n        val strippedName = (name.substring(0, name.indexOf(key)) + name.substring(name.indexOf(host) + host.length, name.length)).replace(\",,\", \",\")\n        c.getMetric.setName(strippedName)\n    }\n    return c\n}\n\ndef stripNames(data: Dataset[Counter]): Dataset[Counter] = {\n    data.map(c => stripServerRuntimes(stripProcessId(c))) (Encoders.bean(classOf[Counter]))\n}\n\ndef nameMetric(name: String, data: Dataset[Counter]): Dataset[Counter] = {\n    data.map(c => {\n        c.getMetric.setName(name + \" : (\" + c.getMetric.getName + \")\")\n        c\n    }) (Encoders.bean(classOf[Counter]))\n}","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nstripProcessId: (c: de.qaware.mlwb.api.Counter)de.qaware.mlwb.api.Counter\n\nstripServerRuntimes: (c: de.qaware.mlwb.api.Counter)de.qaware.mlwb.api.Counter\n\nstripNames: (data: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter])org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n\nnameMetric: (name: String, data: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter])org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n"}]},"apps":[],"jobName":"paragraph_1512380989584_2098898633","id":"20170721-154212_1747862524","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:34"},{"text":"%spark\ndef processFeature(feature: Feature, input: Map[MetricKey, Dataset[Counter]], inTf: Dataset[Counter] => Dataset[Counter]): Dataset[Counter] = {\n    feature match {\n        case m : MetricKey => stripNames(inTf(input.get(m).get))\n        case NamedFeature(n, f) => nameMetric(n, processFeature(f, input, inTf))\n        case Derivative(f) => derive(processFeature(f, input, inTf))\n        case Inclination(f) => max(derive(processFeature(f, input, inTf)), 0.0)\n        case BiCombination(f1, f2, comb) => biCombine(processFeature(f1, input, inTf), processFeature(f2, input, inTf), comb)\n        case LeftCombination(f, const, comb) => leftCombine(processFeature(f, input, inTf), const, comb)\n        case RightCombination(const, f, comb) => rightCombine(const, processFeature(f, input, inTf), comb)\n    }\n}\n\ndef processFeatures(features: Set[Feature], service: MetricsService, start: Timestamp, end: Timestamp): Dataset[Counter] = {\n    val inputData = features.flatMap(extractMetrics(_))\n        .map(m => m -> service.getCounters(new QueryMetricContext.Builder().withMetrics(m.toQueryString).withHost(\"lp*\").withStart(start).withEnd(end).build(), Granularity.MINUTE, AggregationType.MIN))\n        .toMap\n    \n    features\n        .map(processFeature(_, inputData, (x => interpolate(inRange(x.filter(!_.getMetric.getName.contains(\"weblogic.jms.JMSBatch\")))))))\n        .reduce(_.union(_))\n}","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{"0":{"graph":{"mode":"table","height":251.8,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n\n\n\n<console>:127: warning: match may not be exhaustive.\nIt would fail on the following inputs: BiCombination(_, _, _), Derivative(_), Inclination(_), LeftCombination(_, _, _), MetricKey(_, _), NamedFeature(_, _), RightCombination(_, _, _)\n           feature match {\n           ^\n\nprocessFeature: (feature: Feature, input: Map[MetricKey,org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]], inTf: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter] => org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter])org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n\nprocessFeatures: (features: Set[Feature], service: de.qaware.mlwb.api.MetricsService, start: java.sql.Timestamp, end: java.sql.Timestamp)org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter]\n"}]},"apps":[],"jobName":"paragraph_1512380989585_2098513884","id":"20170706-112034_348519821","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:35"},{"text":"%md\n\n# List of all features","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>List of all features</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1512380989585_2098513884","id":"20170720-142101_1554954686","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:36"},{"text":"%spark\ndef explodeBiComb(l: String, r: String, keys: List[String], values: List[List[String]], c: Combinator): Set[Feature] = {\n    values.map(s => keys.zip(s).map(t => t._1 + \"=\" + t._2).toSet).map(s => BiCombination(MetricKey(l, s), MetricKey(r, s), c)).toSet\n}\n\nval datasources = \"source10\" :: (1 to 9).map(\"source0\" + _).toList\n\nvar features = Set[Feature]()\n\nfeatures ++= Set[Feature](\n    NamedFeature(\"Class loading activity\", Derivative(MetricKey(\".LoadedClassCount\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Class unloading activity\", Derivative(MetricKey(\".UnloadedClassCount\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Rel. physical mem usage\", BiCombination(MetricKey(\".FreePhysicalMemorySize\", Set(\"java.lang:type\")), MetricKey(\".TotalPhysicalMemorySize\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"Physical mem activity\", Derivative(MetricKey(\".FreePhysicalMemorySize\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Rel. swap usage\", BiCombination(MetricKey(\".FreeSwapSpaceSize\", Set(\"java.lang:type\")), MetricKey(\".TotalSwapSpaceSize\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"Swap activity\", Derivative(MetricKey(\".FreeSwapSpaceSize\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Rel. open file descriptors\", BiCombination(MetricKey(\".OpenFileDescriptorCount\", Set(\"java.lang:type\")), MetricKey(\".MaxFileDescriptorCount\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"Process CPU\", MetricKey(\".ProcessCpuLoad\", Set(\"java.lang:type\"))),\n    NamedFeature(\"System CPU\", MetricKey(\".SystemCpuLoad\", Set(\"java.lang:type\"))),\n    NamedFeature(\"Failing reserve requests\", Inclination(MetricKey(\".FailedReserveRequestCount\", Set(\"com.bea:Name\", \"Type\")))),\n    NamedFeature(\"Reserve request activity\", Inclination(MetricKey(\".ReserveRequestCount\", Set(\"com.bea:Name\", \"Type\"))))\n)\n\n//new\nfeatures ++= explodeBiComb(\".PrepStmtCacheHitCount\", \".PrepStmtCacheMissCount\", List(\"com.bea:Name\", \"Type\"), datasources.map(List(_, \"*\")), Division).map(NamedFeature(\"Prepared statement cache hit rate\", _))\n\nfeatures ++= Set(\n    NamedFeature(\"Successful wait for connection\", Inclination(MetricKey(\".WaitingForConnectionSuccessTotal\", Set(\"com.bea:Name\", \"Type\")))),\n    NamedFeature(\"Failed wait for connection\", Inclination(MetricKey(\".WaitingForConnectionFailureTotal\", Set(\"com.bea:Name\", \"Type\")))),\n    NamedFeature(\"Rel. heap usage\", BiCombination(MetricKey(\".HeapMemoryUsage.used\", Set(\"java.lang:type\")), MetricKey(\".HeapMemoryUsage.max\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"Rel. heap committed\", BiCombination(MetricKey(\".HeapMemoryUsage.committed\", Set(\"java.lang:type\")), MetricKey(\".HeapMemoryUsage.max\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"Heap usage activity\", Derivative(MetricKey(\".HeapMemoryUsage.used\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Heap committed activity\", Derivative(MetricKey(\".HeapMemoryUsage.committed\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Rel. nonHeap usage\", BiCombination(MetricKey(\".NonHeapMemoryUsage.used\", Set(\"java.lang:type\")), MetricKey(\".NonHeapMemoryUsage.max\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"Rel. nonHeap committed\", BiCombination(MetricKey(\".NonHeapMemoryUsage.committed\", Set(\"java.lang:type\")), MetricKey(\".NonHeapMemoryUsage.max\", Set(\"java.lang:type\")), Division)),\n    NamedFeature(\"NonHeap usage activity\", Derivative(MetricKey(\".NonHeapMemoryUsage.used\", Set(\"java.lang:type\")))),\n    NamedFeature(\"NonHeap committed activity\", Derivative(MetricKey(\".NonHeapMemoryUsage.committed\", Set(\"java.lang:type\")))),\n    NamedFeature(\"Objects to be finalized\", MetricKey(\".ObjectPendingFinalizationCount\", Set(\"java.lang:type\")))\n)\n\nfeatures ++= List(\".Usage.used\", \".Usage.committed\").flatMap(explodeBiComb(_, \".Usage.max\", List(\"java.lang:name\", \"type\"), List(\n    \"Code*Cache\", \n    \"PS*Eden*Space\", \n    \"PS*Old*Gen\", \n    \"PS*Perm*Gen\", \n    \"PS*Survivor*Space\")\n    .map(List(_, \"*\")), Division)).flatMap(x => Iterator(NamedFeature(\"Memory space usage\", x), NamedFeature(\"Memory space activity\", Derivative(x))))\n\nfeatures ++= Set[Feature](\n    NamedFeature(\"Rel. Swap Usage\", BiCombination(MetricKey(\"\\\\Swap\\\\used\", Set()), MetricKey(\"\\\\Swap\\\\total\", Set()), Division)),\n    NamedFeature(\"Stuck threads\", MetricKey(\".StuckThreadCount\", Set(\"com.bea:ApplicationRuntime\", \"Name\", \"Type\"))),\n    NamedFeature(\"Thread CPU time\", MetricKey(\"CurrentThreadCpuTime\", Set(\"java.lang:type\"))),\n    NamedFeature(\"Thread User time\", MetricKey(\"CurrentThreadUserTime\", Set(\"java.lang:type\"))),\n    NamedFeature(\"Daemon thread count\", MetricKey(\".DaemonThreadCount\", Set(\"java.lang:type\"))),\n    NamedFeature(\"Total thread count\", MetricKey(\".ThreadCount\", Set(\"java.lang:type\"))),\n    NamedFeature(\"Active transactions\", MetricKey(\".ActiveTransactionsTotalCount\", Set(\"com.bea:Name\", \"Type\"))),\n    NamedFeature(\"Transaction committ activity\", Inclination(MetricKey(\".TransactionCommittedTotalCount\", Set(\"com.bea:Name\", \"Type\")))),\n    NamedFeature(\"Transaction roll back activity\", Inclination(MetricKey(\".TransactionRolledBackTotalCount\", Set(\"com.bea:Name\", \"Type\")))),\n    NamedFeature(\"Active connections\", MetricKey(\".ActiveConnectionsCurrentCount\", Set(\"com.bea:Name\", \"Type\"))),\n    NamedFeature(\"Connection delay\", MetricKey(\".ConnectionDelayTime\", Set(\"com.bea:Name\", \"Type\"))),\n    NamedFeature(\"DB connection started\", Inclination(MetricKey(\".ConnectionsTotalCount\", Set(\"com.bea:Name\", \"Type\")))),\n    NamedFeature(\"Available db connection activity\", Derivative(MetricKey(\".NumAvailable\", Set(\"com.bea:Name\", \"Type\"))))\n)\n//new\nfeatures ++= explodeBiComb(\".NumUnavailable\", \".CurrCapacity\", List(\"com.bea:Name\", \"Type\"), \n    datasources.flatMap(d => Seq(List(d, \"JDBCDataSourceRuntime\"), List(d, \"JDBCConnectionPoolRuntime\"))), Division)\n    .map(NamedFeature(\"Rel. unavailable connections\", _))\n    \nfeatures ++= Set(\n    NamedFeature(\"Process CPU\", MetricKey(\"\\\\Process(java*)\\\\CPU\", Set())),\n    NamedFeature(\"Stuck threads\", MetricKey(\".StuckThreadCount\", Set(\"com.bea:Name\", \"Type\"))),\n    NamedFeature(\"GC activity\", Inclination(MetricKey(\".CollectionCount\", Set(\"java.lang:name\", \"type\")))),\n    NamedFeature(\"GC time\", Inclination(MetricKey(\".CollectionTime\", Set(\"java.lang:name\", \"type\")))),\n    NamedFeature(\"Last GC duration\", MetricKey(\".LastGcInfo.duration\", Set(\"java.lang:name\", \"type\")))\n)\nfeatures.foreach(println(_))\nfeatures.size","dateUpdated":"2017-12-04T10:49:49+0100","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nexplodeBiComb: (l: String, r: String, keys: List[String], values: List[List[String]], c: Combinator)Set[Feature]\n\ndatasources: List[String] = List(source10, source01, source02, source03, source04, source05, source06, source07, source08, source09)\n\nfeatures: scala.collection.immutable.Set[Feature] = Set()\nNamedFeature(Total thread count,MetricKey(.ThreadCount,Set(java.lang:type)))\nNamedFeature(GC activity,Inclination(MetricKey(.CollectionCount,Set(java.lang:name, type))))\nNamedFeature(Transaction committ activity,Inclination(MetricKey(.TransactionCommittedTotalCount,Set(com.bea:Name, Type))))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source08, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source08, Type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source08, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source08, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Eden*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Eden*Space, type=*)),Division)))\nNamedFeature(Heap usage activity,Derivative(MetricKey(.HeapMemoryUsage.used,Set(java.lang:type))))\nNamedFeature(Active connections,MetricKey(.ActiveConnectionsCurrentCount,Set(com.bea:Name, Type)))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Perm*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Perm*Gen, type=*)),Division))\nNamedFeature(Heap committed activity,Derivative(MetricKey(.HeapMemoryUsage.committed,Set(java.lang:type))))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Survivor*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Survivor*Space, type=*)),Division)))\nNamedFeature(Process CPU,MetricKey(.ProcessCpuLoad,Set(java.lang:type)))\nNamedFeature(Stuck threads,MetricKey(.StuckThreadCount,Set(com.bea:Name, Type)))\nNamedFeature(GC time,Inclination(MetricKey(.CollectionTime,Set(java.lang:name, type))))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Old*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Old*Gen, type=*)),Division)))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source03, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source03, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Last GC duration,MetricKey(.LastGcInfo.duration,Set(java.lang:name, type)))\nNamedFeature(Rel. swap usage,BiCombination(MetricKey(.FreeSwapSpaceSize,Set(java.lang:type)),MetricKey(.TotalSwapSpaceSize,Set(java.lang:type)),Division))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Perm*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Perm*Gen, type=*)),Division))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Perm*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Perm*Gen, type=*)),Division)))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source06, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source06, Type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source04, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source04, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=Code*Cache, type=*)),MetricKey(.Usage.max,Set(java.lang:name=Code*Cache, type=*)),Division))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.used,Set(java.lang:name=Code*Cache, type=*)),MetricKey(.Usage.max,Set(java.lang:name=Code*Cache, type=*)),Division)))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Survivor*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Survivor*Space, type=*)),Division))\nNamedFeature(Rel. nonHeap usage,BiCombination(MetricKey(.NonHeapMemoryUsage.used,Set(java.lang:type)),MetricKey(.NonHeapMemoryUsage.max,Set(java.lang:type)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source10, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source10, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Rel. heap committed,BiCombination(MetricKey(.HeapMemoryUsage.committed,Set(java.lang:type)),MetricKey(.HeapMemoryUsage.max,Set(java.lang:type)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source05, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source05, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source09, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source09, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Thread User time,MetricKey(CurrentThreadUserTime,Set(java.lang:type)))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source06, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source06, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source05, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source05, Type=*)),Division))\nNamedFeature(Failed wait for connection,Inclination(MetricKey(.WaitingForConnectionFailureTotal,Set(com.bea:Name, Type))))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Survivor*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Survivor*Space, type=*)),Division)))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source06, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source06, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Old*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Old*Gen, type=*)),Division)))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source05, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source05, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Daemon thread count,MetricKey(.DaemonThreadCount,Set(java.lang:type)))\nNamedFeature(DB connection started,Inclination(MetricKey(.ConnectionsTotalCount,Set(com.bea:Name, Type))))\nNamedFeature(Available db connection activity,Derivative(MetricKey(.NumAvailable,Set(com.bea:Name, Type))))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Eden*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Eden*Space, type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source10, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source10, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source02, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source02, Type=*)),Division))\nNamedFeature(Rel. open file descriptors,BiCombination(MetricKey(.OpenFileDescriptorCount,Set(java.lang:type)),MetricKey(.MaxFileDescriptorCount,Set(java.lang:type)),Division))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.used,Set(java.lang:name=Code*Cache, type=*)),MetricKey(.Usage.max,Set(java.lang:name=Code*Cache, type=*)),Division))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source10, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source10, Type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source09, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source09, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Connection delay,MetricKey(.ConnectionDelayTime,Set(com.bea:Name, Type)))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Eden*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Eden*Space, type=*)),Division))\nNamedFeature(Transaction roll back activity,Inclination(MetricKey(.TransactionRolledBackTotalCount,Set(com.bea:Name, Type))))\nNamedFeature(Active transactions,MetricKey(.ActiveTransactionsTotalCount,Set(com.bea:Name, Type)))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Survivor*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Survivor*Space, type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source08, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source08, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Reserve request activity,Inclination(MetricKey(.ReserveRequestCount,Set(com.bea:Name, Type))))\nNamedFeature(Thread CPU time,MetricKey(CurrentThreadCpuTime,Set(java.lang:type)))\nNamedFeature(Failing reserve requests,Inclination(MetricKey(.FailedReserveRequestCount,Set(com.bea:Name, Type))))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source02, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source02, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Rel. heap usage,BiCombination(MetricKey(.HeapMemoryUsage.used,Set(java.lang:type)),MetricKey(.HeapMemoryUsage.max,Set(java.lang:type)),Division))\nNamedFeature(Process CPU,MetricKey(\\Process(java*)\\CPU,Set()))\nNamedFeature(System CPU,MetricKey(.SystemCpuLoad,Set(java.lang:type)))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source07, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source07, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(NonHeap committed activity,Derivative(MetricKey(.NonHeapMemoryUsage.committed,Set(java.lang:type))))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source03, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source03, Type=*)),Division))\nNamedFeature(NonHeap usage activity,Derivative(MetricKey(.NonHeapMemoryUsage.used,Set(java.lang:type))))\nNamedFeature(Rel. nonHeap committed,BiCombination(MetricKey(.NonHeapMemoryUsage.committed,Set(java.lang:type)),MetricKey(.NonHeapMemoryUsage.max,Set(java.lang:type)),Division))\nNamedFeature(Rel. Swap Usage,BiCombination(MetricKey(\\Swap\\used,Set()),MetricKey(\\Swap\\total,Set()),Division))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Old*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Old*Gen, type=*)),Division))\nNamedFeature(Rel. physical mem usage,BiCombination(MetricKey(.FreePhysicalMemorySize,Set(java.lang:type)),MetricKey(.TotalPhysicalMemorySize,Set(java.lang:type)),Division))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source07, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source07, Type=*)),Division))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source04, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source04, Type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source02, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source02, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source09, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source09, Type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source03, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source03, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Swap activity,Derivative(MetricKey(.FreeSwapSpaceSize,Set(java.lang:type))))\nNamedFeature(Memory space usage,BiCombination(MetricKey(.Usage.used,Set(java.lang:name=PS*Old*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Old*Gen, type=*)),Division))\nNamedFeature(Successful wait for connection,Inclination(MetricKey(.WaitingForConnectionSuccessTotal,Set(com.bea:Name, Type))))\nNamedFeature(Objects to be finalized,MetricKey(.ObjectPendingFinalizationCount,Set(java.lang:type)))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Perm*Gen, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Perm*Gen, type=*)),Division)))\nNamedFeature(Class unloading activity,Derivative(MetricKey(.UnloadedClassCount,Set(java.lang:type))))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source01, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source01, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=PS*Eden*Space, type=*)),MetricKey(.Usage.max,Set(java.lang:name=PS*Eden*Space, type=*)),Division)))\nNamedFeature(Class loading activity,Derivative(MetricKey(.LoadedClassCount,Set(java.lang:type))))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source07, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source07, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Stuck threads,MetricKey(.StuckThreadCount,Set(com.bea:ApplicationRuntime, Name, Type)))\nNamedFeature(Physical mem activity,Derivative(MetricKey(.FreePhysicalMemorySize,Set(java.lang:type))))\nNamedFeature(Prepared statement cache hit rate,BiCombination(MetricKey(.PrepStmtCacheHitCount,Set(com.bea:Name=source01, Type=*)),MetricKey(.PrepStmtCacheMissCount,Set(com.bea:Name=source01, Type=*)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source01, Type=JDBCDataSourceRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source01, Type=JDBCDataSourceRuntime)),Division))\nNamedFeature(Rel. unavailable connections,BiCombination(MetricKey(.NumUnavailable,Set(com.bea:Name=source04, Type=JDBCConnectionPoolRuntime)),MetricKey(.CurrCapacity,Set(com.bea:Name=source04, Type=JDBCConnectionPoolRuntime)),Division))\nNamedFeature(Memory space activity,Derivative(BiCombination(MetricKey(.Usage.committed,Set(java.lang:name=Code*Cache, type=*)),MetricKey(.Usage.max,Set(java.lang:name=Code*Cache, type=*)),Division)))\n\nres79: Int = 90\n"}]},"apps":[],"jobName":"paragraph_1512380989586_2099668130","id":"20170720-165929_1561998452","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:37"},{"text":"%md\n\n# Call of calculation and write to Solr","dateUpdated":"2017-12-04T10:49:49+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Call of calculation and write to Solr</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1512380989587_2099283382","id":"20171024-095755_1609994658","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:38"},{"text":"%spark\nval start = Timestamp.valueOf(\"2014-11-28 00:00:00\")\nval end = Timestamp.valueOf(\"2015-10-04 00:00:00\")\nval readService = new MetricsServiceImpl.Factory(sqlc).getInstance(\"192.168.1.100:2181\", \"ekgdata\")\nval writeService = new MetricsServiceImpl.Factory(sqlc).getInstance(\"192.168.1.100:2181\", \"rawfeaturedata\")\n\nval allFeatures = processFeatures(features, readService, start, end)\n\nwriteService.putCounters(allFeatures, \"rawfeaturedata\", SaveMode.Ignore)","dateUpdated":"2017-12-04T11:11:58+0100","config":{"tableHide":false,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nstart: java.sql.Timestamp = 2014-11-28 00:00:00.0\n\nend: java.sql.Timestamp = 2015-10-04 00:00:00.0\n\nreadService: de.qaware.mlwb.api.MetricsService = de.qaware.mlwb.impl.sparksolr.MetricsServiceImpl@6ebe220a\n\nwriteService: de.qaware.mlwb.api.MetricsService = de.qaware.mlwb.impl.sparksolr.MetricsServiceImpl@2b3eed4c\n\nprocessedFeatures: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter] = [metric: struct<host: string, name: string ... 1 more field>, valuePoints: array<struct<date:timestamp,value:double>>]\n\nallFeatures: org.apache.spark.sql.Dataset[de.qaware.mlwb.api.Counter] = [metric: struct<host: string, name: string ... 1 more field>, valuePoints: array<struct<date:timestamp,value:double>>]\n"}]},"apps":[],"jobName":"paragraph_1512380989587_2099283382","id":"20170718-141932_1897495706","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:39"},{"text":"","dateUpdated":"2017-12-04T10:49:49+0100","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1512380989588_2097359637","id":"20170803-092726_654890728","dateCreated":"2017-12-04T10:49:49+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:40"}],"name":"AnomalyDetectionML/Processing/02 Feature Raw","id":"2D1V68S3P","angularObjects":{"2CZ6JJTDR:shared_process":[],"2CZU9K4SP:shared_process":[],"2CYR4Y5D7:shared_process":[],"2D33TFRH4:shared_process":[],"2D18HK2TW:shared_process":[],"2D15EVSM5:shared_process":[],"2D2FQENTY:shared_process":[],"2CY5C8M4U:shared_process":[],"2CZGJ6DT8:shared_process":[],"2D2H4Y35Y:shared_process":[],"2D21J2RXK:shared_process":[],"2D2QUK9JC:shared_process":[],"2CYJWH63V:shared_process":[],"2D2XZGK45:shared_process":[],"2D1F6X9XF:shared_process":[],"2CY8V4V41:shared_process":[],"2D1JVM9EC:shared_process":[],"2D2NZHKM4:shared_process":[],"2D2E56F9K:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}